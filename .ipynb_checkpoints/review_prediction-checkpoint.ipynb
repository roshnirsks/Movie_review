{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "en_stopwords=set(stopwords.words('english'))\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstemmedreview(review):\n",
    "    review=review.lower()\n",
    "    review=review.replace('<br><br>',\" \")\n",
    "    tokens=tokenizer.tokenize(review)\n",
    "    new_tokens=[i for i in tokens if i not in en_stopwords]\n",
    "    stemmed_tokens=[ps.stem(i) for i in new_tokens]\n",
    "    \n",
    "    cleared_review=' '.join(stemmed_tokens)\n",
    "    return cleared_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ashutosh nice guy behav realli well class teacher alway like'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getstemmedreview('ashutosh is a nice guy and he behaves really well in the class so teacher always likes him')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstemmeddoc(inputfile,outputfile):\n",
    "    out=open(outputfile,'w',encoding='utf8')\n",
    "    \n",
    "    with open(inputfile,encoding='utf8') as f:\n",
    "        reviews=f.readlines()\n",
    "        \n",
    "    for review in reviews:\n",
    "        cleaned_review=getstemmedreview(review)\n",
    "        print((cleaned_review),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a660f197545e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minputfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutputfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgetstemmeddoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-7b8a43fb7033>\u001b[0m in \u001b[0;36mgetstemmeddoc\u001b[1;34m(inputfile, outputfile)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mreviews\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "inputfile=sys.argv[1]\n",
    "outputfile=sys.argv[2]\n",
    "getstemmeddoc(inputfile,outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleaned_review as ct\n",
    "x=['this was an awesome movie',\n",
    "  'movie was really great and i enjoyed a lot',\n",
    "  'fantastic movie it was and i really really loved this movie',\n",
    "  'loved it! Truely great',\n",
    "  'could have been better',\n",
    "  'surely a disappointing movie',\n",
    "  'worst not upto that mark']\n",
    "y=[1,1,1,1,0,0,0]\n",
    "x_test=['i was happy and i loved acting in the movie',\n",
    "       'the movie i saw was not bad ']\n",
    "y_test=[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesom movi', 'movi realli great enjoy lot', 'fantast movi realli realli love movi', 'love trueli great', 'could better', 'sure disappoint movi', 'worst upto mark']\n"
     ]
    }
   ],
   "source": [
    "x_clean=[ct.getstemmedreview(i) for i in x]\n",
    "xt_clean=[ct.getstemmedreview(i) for i in x_test]\n",
    "print(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 2 1 0 1 2 0 0 1 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  1 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 1 1 1 1]]\n",
      "(7, 42)\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "x_vec=cv.fit_transform(x_clean).toarray()\n",
    "print(x_vec)\n",
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesom', 'awesom movi', 'better', 'could', 'could better', 'disappoint', 'disappoint movi', 'enjoy', 'enjoy lot', 'fantast', 'fantast movi', 'fantast movi realli', 'great', 'great enjoy', 'great enjoy lot', 'lot', 'love', 'love movi', 'love trueli', 'love trueli great', 'mark', 'movi', 'movi realli', 'movi realli great', 'movi realli realli', 'realli', 'realli great', 'realli great enjoy', 'realli love', 'realli love movi', 'realli realli', 'realli realli love', 'sure', 'sure disappoint', 'sure disappoint movi', 'trueli', 'trueli great', 'upto', 'upto mark', 'worst', 'worst upto', 'worst upto mark']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]]\n",
      "(2, 42)\n",
      "['awesom', 'awesom movi', 'better', 'could', 'could better', 'disappoint', 'disappoint movi', 'enjoy', 'enjoy lot', 'fantast', 'fantast movi', 'fantast movi realli', 'great', 'great enjoy', 'great enjoy lot', 'lot', 'love', 'love movi', 'love trueli', 'love trueli great', 'mark', 'movi', 'movi realli', 'movi realli great', 'movi realli realli', 'realli', 'realli great', 'realli great enjoy', 'realli love', 'realli love movi', 'realli realli', 'realli realli love', 'sure', 'sure disappoint', 'sure disappoint movi', 'trueli', 'trueli great', 'upto', 'upto mark', 'worst', 'worst upto', 'worst upto mark']\n"
     ]
    }
   ],
   "source": [
    "xt_vec=cv.transform(x_test).toarray()\n",
    "print(xt_vec)\n",
    "print(xt_vec.shape)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(xt_vec,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
